import os
import spacy
import fitz  # PyMuPDF for PDFs
import docx2txt  # Extract text from Word docs
import openai
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Load the Spacy NLP model
nlp = spacy.load("en_core_web_sm")

# Function to extract text from a resume
def extract_text_from_resume(file_path):
    text = ""
    if file_path.endswith(".pdf"):
        with fitz.open(file_path) as doc:
            for page in doc:
                text += page.get_text("text")
    elif file_path.endswith(".docx"):
        text = docx2txt.process(file_path)
    return text.strip()

# Function to process text (cleaning and tokenizing)
def process_text(text):
    doc = nlp(text.lower())  # Convert to lowercase for normalization
    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]
    return " ".join(tokens)

# Function to extract key skills from text
def extract_skills(text):
    doc = nlp(text)
    skills = [token.text for token in doc if token.pos_ in ["NOUN", "PROPN"]]
    return [skill[0] for skill in Counter(skills).most_common(10)]  # Return top 10 skills

# Resume matching algorithm using TF-IDF and Cosine Similarity
def match_resumes(job_desc, resumes):
    processed_job_desc = process_text(job_desc)
    processed_resumes = [process_text(resume) for resume in resumes]

    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([processed_job_desc] + processed_resumes)
    
    scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()
    return scores

# OpenAI API Key (Replace with your actual key)
openai.api_key = "your-api-key"

# OpenAI API for AI-Powered Resume Ranking Explanation
def explain_ranking(resume_text, job_desc):
    prompt = f"""
    Job Description: {job_desc}
    Resume: {resume_text}
    
    Analyze the resume and explain how well it matches the job description in simple terms.
    """
    
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "system", "content": "You are a professional HR assistant."},
                  {"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]
